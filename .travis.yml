language: python
python:
  - "2.7"
  - "3.5"
  - "3.6"
  - "3.7"
dist: xenial
sudo: true
before_install:
  - sudo apt-get install libc6
  - sudo apt-get install gfortran
  # pyspark
  - curl -L -o spark.tgz https://s3.amazonaws.com/spark-related-packages/spark-2.2.0-bin-hadoop2.7.tgz
  - export SPARK_HOME=./local/spark
  - mkdir -p "$SPARK_HOME"
  - tar -xf spark.tgz -C "$SPARK_HOME" --strip-components=1
  - export PATH="$SPARK_HOME/bin:$PATH"
  - export SPARK_LOCAL_IP="127.0.0.1"
  # These lines here just suppress a lot of noisy log messages from Spark.
  - echo "log4j.logger.org.apache.spark=WARN" > "$SPARK_HOME"/conf/log4j.properties
  - echo "log4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR" >> "$SPARK_HOME"/conf/log4j.properties
  - echo "log4j.logger.org.apache.parquet=ERROR" >> "$SPARK_HOME"/conf/log4j.properties
install:
  - pip install -U pandas
  - pip install -U .
# command to run tests
script:
  - spark-submit setup.py test # or py.test for Python versions 3.5 and below
